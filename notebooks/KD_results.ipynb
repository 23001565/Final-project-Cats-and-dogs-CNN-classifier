{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyO1VwNQY7FP/36ewjbvu1sH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["#Finetune pretrained teacher"],"metadata":{"id":"yGger-pC2rla"}},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torchvision.models as models\n","import torchvision.transforms as transforms\n","from torch.utils.data import DataLoader\n","from torchvision.datasets import ImageFolder\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"],"metadata":{"id":"UBTgcsIHh-yV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torchvision.models import resnet50\n","from torchvision import models\n","from torch import nn"],"metadata":{"id":"PNskm-lOh-yW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["teacher_model = models.resnet50(weights='IMAGENET1K_V1')\n","num_ftrs = teacher_model.fc.in_features\n","\n","# Change last layer to output 2 classes (cat, dog)\n","teacher_model.fc = nn.Linear(num_ftrs, 2)\n","teacher_model = teacher_model.to(device)\n"],"metadata":{"executionInfo":{"status":"ok","timestamp":1763972687621,"user_tz":-420,"elapsed":1223,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"colab":{"base_uri":"https://localhost:8080/"},"id":"YTxg7jyPh-yX","outputId":"e604066b-ed00-4c54-f522-fbd9b0f3ee23"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 97.8M/97.8M [00:00<00:00, 203MB/s]\n"]}]},{"cell_type":"code","source":["# Freeze all except last block + fc\n","for name, param in teacher_model.named_parameters():\n","    if \"layer4\" not in name and \"fc\" not in name:\n","        param.requires_grad = False\n","\n","optimizer = torch.optim.Adam([\n","    {'params': teacher_model.layer4.parameters(), 'lr': 1e-4},\n","    {'params': teacher_model.fc.parameters(), 'lr': 1e-3}\n","], weight_decay=1e-4)\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"c3yD1Gc4h-yX"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763972828709,"user_tz":-420,"elapsed":1617,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"4710814f-22df-4eea-94c8-5e3f28089fdb","id":"74ExZSJUqvOC"},"source":["# Define paths to your labeled datasets\n","finetune_dir = '/content/drive/MyDrive/pets/finetune_train'\n","val_dir = '/content/drive/MyDrive/pets/val'\n","\n","IMG_SIZE = 224  # Standard input size for ResNet models\n","BATCH_SIZE = 64\n","\n","# Define transforms for training with augmentation\n","transform_train = transforms.Compose([\n","    transforms.RandomResizedCrop(IMG_SIZE, scale=(0.8, 1.0)), # Add RandomResizedCrop\n","    transforms.RandomHorizontalFlip(),        # Randomly flip images horizontally\n","    transforms.RandomRotation(15),            # Add RandomRotation\n","    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.4, hue=0.2), # Add ColorJitter\n","    transforms.ToTensor(),                    # Convert images to PyTorch tensors\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet stats\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# Define transforms for validation without augmentation\n","transform_val = transforms.Compose([\n","    transforms.Resize((IMG_SIZE, IMG_SIZE)),  # Resize images\n","    transforms.ToTensor(),                    # Convert images to PyTorch tensors\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # Normalize with ImageNet stats\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# Create ImageFolder datasets\n","finetune_dataset = ImageFolder(finetune_dir, transform=transform_train)\n","val_dataset = ImageFolder(val_dir, transform=transform_val)\n","\n","# Create DataLoaders\n","finetune_loader = DataLoader(finetune_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n","\n","print(\"Finetune dataset size:\", len(finetune_dataset))\n","print(\"Validation dataset size:\", len(val_dataset))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetune dataset size: 420\n","Validation dataset size: 180\n"]}]},{"cell_type":"code","source":["teacher_model = models.resnet50(weights='ResNet50_Weights.IMAGENET1K_V1')\n","num_ftrs = teacher_model.fc.in_features\n","\n","# Change last layer to output 2 classes (cat, dog)\n","teacher_model.fc = nn.Linear(num_ftrs, 2)\n","teacher_model = teacher_model.to(device)\n"],"metadata":{"id":"AiIG5VfpJbuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Freeze all except last block + fc\n","for name, param in teacher_model.named_parameters():\n","    if \"layer4\" not in name and \"fc\" not in name:\n","        param.requires_grad = False\n","\n","optimizer = torch.optim.Adam([\n","    {'params': teacher_model.layer4.parameters(), 'lr': 1e-4},\n","    {'params': teacher_model.fc.parameters(), 'lr': 1e-3}\n","], weight_decay=1e-4)\n","criterion = nn.CrossEntropyLoss()\n"],"metadata":{"id":"87Cv9gtIJbuM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_epoch(model, dataloader, criterion, optimizer, device):\n","    teacher_model.train()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    for imgs, labels in dataloader:\n","        imgs, labels = imgs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","        outputs = model(imgs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","\n","        running_loss += loss.item() * imgs.size(0)\n","        _, preds = torch.max(outputs, 1)\n","        correct += (preds == labels).sum().item()\n","        total += labels.size(0)\n","\n","    epoch_loss = running_loss / total\n","    epoch_acc = correct / total\n","    return epoch_loss, epoch_acc\n","\n","def validate(model, dataloader, criterion, device):\n","    teacher_model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc\n"],"metadata":{"id":"WjLjqQOiJbuN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss, train_acc = train_epoch(teacher_model, finetune_loader, criterion, optimizer, device)\n","    val_loss, val_acc = validate(teacher_model, val_loader, criterion, device)\n","\n","    print(f'Epoch {epoch+1}: '\n","          f'Train Loss: {train_loss:.4f} Acc: {train_acc:.4f} | '\n","          f'Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763973104374,"user_tz":-420,"elapsed":143739,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"ee53af5d-c0ce-4ad8-b2c6-963839e11c80","id":"MhbKAvhmJbuN"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss: 0.2912 Acc: 0.8810 | Val Loss: 0.0462 Acc: 0.9778\n","Epoch 2: Train Loss: 0.0463 Acc: 0.9857 | Val Loss: 0.0556 Acc: 0.9778\n","Epoch 3: Train Loss: 0.0266 Acc: 0.9905 | Val Loss: 0.1259 Acc: 0.9778\n","Epoch 4: Train Loss: 0.0108 Acc: 0.9952 | Val Loss: 0.1084 Acc: 0.9778\n","Epoch 5: Train Loss: 0.0138 Acc: 0.9952 | Val Loss: 0.1097 Acc: 0.9722\n"]}]},{"cell_type":"code","source":["import os\n","save_path = '/content/drive/MyDrive/mods/resnet_finetune_only.pth'\n","os.makedirs(os.path.dirname(save_path), exist_ok=True)"],"metadata":{"id":"6gB2jrO-_Wzs"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(teacher_model.state_dict(), save_path)"],"metadata":{"id":"IpMkXlCrp8Fe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#3000set"],"metadata":{"id":"v8NOdRr1DLID"}},{"cell_type":"markdown","source":["##Distillation"],"metadata":{"id":"uo_k6gbsh-yd"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763974311242,"user_tz":-420,"elapsed":89,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"cf0ea885-19b4-44c3-af6e-a450e783ff88","id":"a3pmI0T-h-yd"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","\n","# Instantiate MobileNetV2 without pretrained weights\n","student = models.mobilenet_v2(weights=None)\n","\n","# Replace the default classifier with a new linear layer for 2 classes\n","# The last_channel attribute gives the input features to the original classifier\n","num_classes = 2\n","student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n","\n","print(\"MobileNetV2 student model defined with classification head.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2 student model defined with classification head.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763974343029,"user_tz":-420,"elapsed":545,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"3ce2a6df-e98f-48f5-ba32-430961abdeb8","id":"kOOKROm9h-ye"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","\n","# Define the path to your saved finetuned teacher model checkpoint\n","finetuned_checkpoint_path = save_path\n","\n","# Load a standard ResNet50 model structure\n","teacher_model = models.resnet50(weights=None) # Load without pretrained ImageNet weights initially\n","\n","# Modify the final fully connected layer to match the number of classes\n","num_ftrs = teacher_model.fc.in_features\n","num_classes = 2  # Your model was finetuned for 2 classes (Cat/Dog)\n","teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n","\n","\n","# Load the state dictionary from the saved finetuned teacher model checkpoint\n","# Using map_location='cpu' to load onto CPU first is safer, then move to device\n","teacher_state_dict = torch.load(finetuned_checkpoint_path, map_location='cpu')\n","\n","# Load the state dictionary into the standard ResNet50 model\n","# This should now work because the model structure matches the saved state_dict\n","teacher_model.load_state_dict(teacher_state_dict)\n","\n","# Set the teacher model to evaluation mode\n","teacher_model.eval()\n","\n","# Freeze the teacher model parameters\n","for param in teacher_model.parameters():\n","    param.requires_grad = False\n","\n","# Determine the device based on CUDA availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the teacher model to the device\n","teacher_model = teacher_model.to(device)\n","\n","print(\"Finetuned teacher model loaded for distillation.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned teacher model loaded for distillation.\n"]}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- transforms ---\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# --- datasets ---\n","unlabeled = '/content/drive/MyDrive/pets/train3000'\n","labeled = '/content/drive/MyDrive/pets/finetune_train'\n","val = '/content/drive/MyDrive/pets/val'\n","\n","# Load datasets\n","labeled_dataset = datasets.ImageFolder(labeled, transform=train_transform)\n","unlabeled_dataset = datasets.ImageFolder(unlabeled, transform=train_transform)\n","\n","\n","# Replace labels for unlabeled samples with -1\n","unlabeled_dataset.samples = [(path, -1) for (path, _) in unlabeled_dataset.samples]\n","\n","BATCH_SIZE = 64\n","\n","# Combine\n","combined_dataset = ConcatDataset([labeled_dataset, unlabeled_dataset])\n","train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","val_dataset = datasets.ImageFolder(val, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"Number of images in the labeled dataset: {len(labeled_dataset)}\")\n","print(f\"Number of images in the unlabeled dataset: {len(unlabeled_dataset)}\")\n","print(f\"Number of images in the val dataset: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763974363581,"user_tz":-420,"elapsed":4218,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"9c99f78d-0c3f-4dd5-ef08-5a824b90f8b6","id":"5N5WFG_Mh-ye"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the labeled dataset: 420\n","Number of images in the unlabeled dataset: 3000\n","Number of images in the val dataset: 180\n"]}]},{"cell_type":"code","source":["ce_loss = nn.CrossEntropyLoss()\n","\n","def kd_loss(student_logits, teacher_logits, T):\n","    \"\"\"KL divergence loss for soft logits.\"\"\"\n","    p_s = F.log_softmax(student_logits / T, dim=1)\n","    p_t = F.softmax(teacher_logits / T, dim=1)\n","    return F.kl_div(p_s, p_t, reduction='batchmean') * (T * T)"],"metadata":{"id":"Aps_wzqAh-ye"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_distillation_epoch(student_model, teacher_model, dataloader, criterion_ce, criterion_kd, optimizer, T, device, alpha):\n","    student_model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get teacher and student outputs\n","        with torch.no_grad():\n","            teacher_logits = teacher_model(inputs)\n","        student_logits = student_model(inputs)\n","\n","        # Identify labeled and unlabeled samples\n","        labeled_mask = (labels != -1)\n","        unlabeled_mask = (labels == -1)\n","\n","        # Calculate loss for labeled data (Cross-Entropy)\n","        ce_loss = criterion_ce(student_logits[labeled_mask], labels[labeled_mask]) if labeled_mask.sum() > 0 else 0\n","\n","        # Calculate loss for unlabeled data (KL Divergence)\n","        kd_loss_val = criterion_kd(student_logits[unlabeled_mask], teacher_logits[unlabeled_mask], T) if unlabeled_mask.sum() > 0 else 0\n","\n","        # Combine losses\n","        loss = (1 - alpha) * ce_loss + alpha * kd_loss_val\n","\n","        # Backpropagate and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss and accuracy\n","        running_loss += loss.item() * inputs.size(0)\n","        # For accuracy, only consider labeled data\n","        if labeled_mask.sum() > 0:\n","            _, preds = torch.max(student_logits[labeled_mask], 1)\n","            correct += (preds == labels[labeled_mask]).sum().item()\n","            total += labeled_mask.sum().item()\n","\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / total if total > 0 else 0.0\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"_2X6L5Meh-yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc"],"metadata":{"id":"76vqwd34h-yf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_student = torch.optim.Adam(student.parameters(), lr=3e-4) # Define optimizer for student\n","T = 5.0 # Temperature for KL divergence\n","alpha = 0.7\n","# Move student model to device\n","student = student.to(device)\n","\n","for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+1}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"id":"RWEKpQHch-yf","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763975303542,"user_tz":-420,"elapsed":855689,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"34d2b013-c96d-4aba-ebd8-8df6e6ae2178"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss (Student): 5.1931 Acc (Labeled): 0.5214 | Val Loss (Student): 0.7039 Acc: 0.5000\n","Epoch 2: Train Loss (Student): 5.1687 Acc (Labeled): 0.5714 | Val Loss (Student): 0.7169 Acc: 0.5778\n","Epoch 3: Train Loss (Student): 5.0559 Acc (Labeled): 0.5857 | Val Loss (Student): 0.8445 Acc: 0.5167\n","Epoch 4: Train Loss (Student): 4.8943 Acc (Labeled): 0.5833 | Val Loss (Student): 2.1410 Acc: 0.5222\n","Epoch 5: Train Loss (Student): 4.7934 Acc (Labeled): 0.6381 | Val Loss (Student): 0.7734 Acc: 0.6167\n","Epoch 6: Train Loss (Student): 4.7095 Acc (Labeled): 0.6286 | Val Loss (Student): 1.2636 Acc: 0.5889\n","Epoch 7: Train Loss (Student): 4.6460 Acc (Labeled): 0.6357 | Val Loss (Student): 0.7221 Acc: 0.7167\n","Epoch 8: Train Loss (Student): 4.5148 Acc (Labeled): 0.6095 | Val Loss (Student): 0.7326 Acc: 0.7111\n","Epoch 9: Train Loss (Student): 4.5226 Acc (Labeled): 0.6500 | Val Loss (Student): 0.9390 Acc: 0.6444\n","Epoch 10: Train Loss (Student): 4.4434 Acc (Labeled): 0.6810 | Val Loss (Student): 0.7981 Acc: 0.7500\n"]}]},{"cell_type":"code","source":["torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_3000.pth')"],"metadata":{"id":"tYZ-CWLHmsyc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+11}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763975810509,"user_tz":-420,"elapsed":424760,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"569ba1f6-4f48-498a-ac13-f7c9764069d9","id":"bLZTe4nQh-yf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 11: Train Loss (Student): 4.3120 Acc (Labeled): 0.6619 | Val Loss (Student): 0.7002 Acc: 0.7389\n","Epoch 12: Train Loss (Student): 4.2053 Acc (Labeled): 0.6667 | Val Loss (Student): 0.6846 Acc: 0.7389\n","Epoch 13: Train Loss (Student): 4.1170 Acc (Labeled): 0.6881 | Val Loss (Student): 0.6656 Acc: 0.7556\n","Epoch 14: Train Loss (Student): 4.1401 Acc (Labeled): 0.6833 | Val Loss (Student): 0.7854 Acc: 0.7222\n","Epoch 15: Train Loss (Student): 3.9562 Acc (Labeled): 0.7143 | Val Loss (Student): 0.9036 Acc: 0.7500\n","Epoch 16: Train Loss (Student): 3.9139 Acc (Labeled): 0.7000 | Val Loss (Student): 0.9829 Acc: 0.7056\n","Epoch 17: Train Loss (Student): 3.9514 Acc (Labeled): 0.6786 | Val Loss (Student): 0.6888 Acc: 0.7556\n","Epoch 18: Train Loss (Student): 3.8844 Acc (Labeled): 0.6881 | Val Loss (Student): 2.1505 Acc: 0.5944\n","Epoch 19: Train Loss (Student): 3.8501 Acc (Labeled): 0.7476 | Val Loss (Student): 0.8681 Acc: 0.7389\n","Epoch 20: Train Loss (Student): 3.7870 Acc (Labeled): 0.7333 | Val Loss (Student): 0.7242 Acc: 0.7722\n"]}]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+21}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763976080977,"user_tz":-420,"elapsed":211418,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"3f53c48b-f86c-44ac-c5d3-f10f7c7e50a5","id":"Nm0Si_Fnh-yf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21: Train Loss (Student): 3.7003 Acc (Labeled): 0.7333 | Val Loss (Student): 0.8330 Acc: 0.8000\n","Epoch 22: Train Loss (Student): 3.6804 Acc (Labeled): 0.7119 | Val Loss (Student): 0.6037 Acc: 0.8000\n","Epoch 23: Train Loss (Student): 3.6028 Acc (Labeled): 0.7190 | Val Loss (Student): 0.5855 Acc: 0.8167\n","Epoch 24: Train Loss (Student): 3.6279 Acc (Labeled): 0.7667 | Val Loss (Student): 0.5893 Acc: 0.8056\n","Epoch 25: Train Loss (Student): 3.5635 Acc (Labeled): 0.7452 | Val Loss (Student): 0.7243 Acc: 0.7889\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"RJpSD3rUh-yh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#6000SET"],"metadata":{"id":"7kMaRPi9Lq8i"}},{"cell_type":"markdown","source":["##Distillation"],"metadata":{"id":"uPGMFwYDL16-"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763976533643,"user_tz":-420,"elapsed":52,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"e794ac6e-85c0-4e9c-8356-47ceacdab16b","id":"Zal4gh55L16-"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","\n","# Instantiate MobileNetV2 without pretrained weights\n","student = models.mobilenet_v2(weights=None)\n","\n","# Replace the default classifier with a new linear layer for 2 classes\n","# The last_channel attribute gives the input features to the original classifier\n","num_classes = 2\n","student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n","\n","print(\"MobileNetV2 student model defined with classification head.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2 student model defined with classification head.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763976530254,"user_tz":-420,"elapsed":570,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"0ddb33be-1153-4442-8d5e-dbf4163d4e7b","id":"1lM4JF_kL16-"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","\n","# Define the path to your saved finetuned teacher model checkpoint\n","finetuned_checkpoint_path = save_path\n","\n","# Load a standard ResNet50 model structure\n","teacher_model = models.resnet50(weights=None) # Load without pretrained ImageNet weights initially\n","\n","# Modify the final fully connected layer to match the number of classes\n","num_ftrs = teacher_model.fc.in_features\n","num_classes = 2  # Your model was finetuned for 2 classes (Cat/Dog)\n","teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n","\n","\n","# Load the state dictionary from the saved finetuned teacher model checkpoint\n","# Using map_location='cpu' to load onto CPU first is safer, then move to device\n","teacher_state_dict = torch.load(finetuned_checkpoint_path, map_location='cpu')\n","\n","# Load the state dictionary into the standard ResNet50 model\n","# This should now work because the model structure matches the saved state_dict\n","teacher_model.load_state_dict(teacher_state_dict)\n","\n","# Set the teacher model to evaluation mode\n","teacher_model.eval()\n","\n","# Freeze the teacher model parameters\n","for param in teacher_model.parameters():\n","    param.requires_grad = False\n","\n","# Determine the device based on CUDA availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the teacher model to the device\n","teacher_model = teacher_model.to(device)\n","\n","print(\"Finetuned teacher model loaded for distillation.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned teacher model loaded for distillation.\n"]}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- transforms ---\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# --- datasets ---\n","unlabeled = '/content/drive/MyDrive/pets/train6000'\n","#labeled = '/content/drive/MyDrive/pets/finetune_train'\n","#val = '/content/drive/MyDrive/pets/val'\n","\n","# Load datasets\n","#labeled_dataset = datasets.ImageFolder(labeled, transform=train_transform)\n","unlabeled_dataset = datasets.ImageFolder(unlabeled, transform=train_transform)\n","\n","\n","# Replace labels for unlabeled samples with -1\n","unlabeled_dataset.samples = [(path, -1) for (path, _) in unlabeled_dataset.samples]\n","\n","BATCH_SIZE = 64\n","\n","# Combine\n","combined_dataset = ConcatDataset([labeled_dataset, unlabeled_dataset])\n","train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","#val_dataset = datasets.ImageFolder(val, transform=val_transform)\n","#val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"Number of images in the labeled dataset: {len(labeled_dataset)}\")\n","print(f\"Number of images in the unlabeled dataset: {len(unlabeled_dataset)}\")\n","print(f\"Number of images in the val dataset: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763976519830,"user_tz":-420,"elapsed":8926,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"9f3f6560-bbda-4d15-ec48-ac972d60f648","id":"45AeZvarL16_"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the labeled dataset: 420\n","Number of images in the unlabeled dataset: 6000\n","Number of images in the val dataset: 180\n"]}]},{"cell_type":"code","source":["ce_loss = nn.CrossEntropyLoss()\n","\n","def kd_loss(student_logits, teacher_logits, T):\n","    \"\"\"KL divergence loss for soft logits.\"\"\"\n","    p_s = F.log_softmax(student_logits / T, dim=1)\n","    p_t = F.softmax(teacher_logits / T, dim=1)\n","    return F.kl_div(p_s, p_t, reduction='batchmean') * (T * T)"],"metadata":{"id":"321afpjRL16_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_distillation_epoch(student_model, teacher_model, dataloader, criterion_ce, criterion_kd, optimizer, T, device, alpha):\n","    student_model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get teacher and student outputs\n","        with torch.no_grad():\n","            teacher_logits = teacher_model(inputs)\n","        student_logits = student_model(inputs)\n","\n","        # Identify labeled and unlabeled samples\n","        labeled_mask = (labels != -1)\n","        unlabeled_mask = (labels == -1)\n","\n","        # Calculate loss for labeled data (Cross-Entropy)\n","        ce_loss = criterion_ce(student_logits[labeled_mask], labels[labeled_mask]) if labeled_mask.sum() > 0 else 0\n","\n","        # Calculate loss for unlabeled data (KL Divergence)\n","        kd_loss_val = criterion_kd(student_logits[unlabeled_mask], teacher_logits[unlabeled_mask], T) if unlabeled_mask.sum() > 0 else 0\n","\n","        # Combine losses\n","        loss = (1 - alpha) * ce_loss + alpha * kd_loss_val\n","\n","        # Backpropagate and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss and accuracy\n","        running_loss += loss.item() * inputs.size(0)\n","        # For accuracy, only consider labeled data\n","        if labeled_mask.sum() > 0:\n","            _, preds = torch.max(student_logits[labeled_mask], 1)\n","            correct += (preds == labels[labeled_mask]).sum().item()\n","            total += labeled_mask.sum().item()\n","\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / total if total > 0 else 0.0\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"j1XF2sxzL16_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc"],"metadata":{"id":"v5x1l7eaL17A"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_student = torch.optim.Adam(student.parameters(), lr=3e-4) # Define optimizer for student\n","T = 5.0 # Temperature for KL divergence\n","alpha = 0.7\n","# Move student model to device\n","student = student.to(device)\n","\n","for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+1}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763977790658,"user_tz":-420,"elapsed":1238817,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"6777d383-3523-44ee-f0f3-2fd066dcffd7","id":"gtimP5d0L17A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss (Student): 5.1842 Acc (Labeled): 0.5381 | Val Loss (Student): 0.6721 Acc: 0.5556\n","Epoch 2: Train Loss (Student): 5.0698 Acc (Labeled): 0.5452 | Val Loss (Student): 1.4788 Acc: 0.5167\n","Epoch 3: Train Loss (Student): 4.8110 Acc (Labeled): 0.6000 | Val Loss (Student): 0.6650 Acc: 0.6667\n","Epoch 4: Train Loss (Student): 4.6098 Acc (Labeled): 0.6238 | Val Loss (Student): 0.8363 Acc: 0.6889\n","Epoch 5: Train Loss (Student): 4.4442 Acc (Labeled): 0.6738 | Val Loss (Student): 0.9813 Acc: 0.7056\n","Epoch 6: Train Loss (Student): 4.3574 Acc (Labeled): 0.6619 | Val Loss (Student): 1.0877 Acc: 0.7278\n","Epoch 7: Train Loss (Student): 4.1749 Acc (Labeled): 0.7167 | Val Loss (Student): 0.8840 Acc: 0.7222\n","Epoch 8: Train Loss (Student): 4.0479 Acc (Labeled): 0.7071 | Val Loss (Student): 0.6472 Acc: 0.7500\n","Epoch 9: Train Loss (Student): 4.0704 Acc (Labeled): 0.7095 | Val Loss (Student): 0.6726 Acc: 0.7833\n","Epoch 10: Train Loss (Student): 3.9455 Acc (Labeled): 0.7452 | Val Loss (Student): 0.8921 Acc: 0.7667\n"]}]},{"cell_type":"code","source":["for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+11}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763978624029,"user_tz":-420,"elapsed":768055,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"8b461540-19b0-4f7c-f93a-fb3d75001f79","id":"JMlr_Uw3L17A"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 11: Train Loss (Student): 3.8369 Acc (Labeled): 0.7357 | Val Loss (Student): 1.0122 Acc: 0.7278\n","Epoch 12: Train Loss (Student): 3.7176 Acc (Labeled): 0.7214 | Val Loss (Student): 0.6087 Acc: 0.7944\n","Epoch 13: Train Loss (Student): 3.7597 Acc (Labeled): 0.7286 | Val Loss (Student): 0.7711 Acc: 0.7444\n","Epoch 14: Train Loss (Student): 3.6544 Acc (Labeled): 0.7738 | Val Loss (Student): 0.6089 Acc: 0.7889\n","Epoch 15: Train Loss (Student): 3.4878 Acc (Labeled): 0.7500 | Val Loss (Student): 0.7014 Acc: 0.7667\n","Epoch 16: Train Loss (Student): 3.6015 Acc (Labeled): 0.7524 | Val Loss (Student): 0.9612 Acc: 0.7889\n","Epoch 17: Train Loss (Student): 3.4703 Acc (Labeled): 0.7190 | Val Loss (Student): 0.6568 Acc: 0.8111\n","Epoch 18: Train Loss (Student): 3.3336 Acc (Labeled): 0.7571 | Val Loss (Student): 0.8136 Acc: 0.7833\n","Epoch 19: Train Loss (Student): 3.2784 Acc (Labeled): 0.7690 | Val Loss (Student): 0.6788 Acc: 0.8500\n","Epoch 20: Train Loss (Student): 3.1939 Acc (Labeled): 0.7548 | Val Loss (Student): 0.6982 Acc: 0.7944\n"]}]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+21}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763979034669,"user_tz":-420,"elapsed":388076,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"8498bd70-7b64-4bde-98cb-f9b6225d7f1b","id":"fvt4Dj5qL17B"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 21: Train Loss (Student): 3.1795 Acc (Labeled): 0.7571 | Val Loss (Student): 0.6118 Acc: 0.8389\n","Epoch 22: Train Loss (Student): 3.1541 Acc (Labeled): 0.8048 | Val Loss (Student): 0.4959 Acc: 0.8444\n","Epoch 23: Train Loss (Student): 2.9786 Acc (Labeled): 0.7857 | Val Loss (Student): 0.4949 Acc: 0.8444\n","Epoch 24: Train Loss (Student): 3.0608 Acc (Labeled): 0.8000 | Val Loss (Student): 0.4247 Acc: 0.8667\n","Epoch 25: Train Loss (Student): 3.0114 Acc (Labeled): 0.8143 | Val Loss (Student): 0.5318 Acc: 0.8778\n"]}]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+26}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763979452177,"user_tz":-420,"elapsed":380376,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"bff1ac9c-7432-41ab-d81c-83919cdb13ff","id":"PH97gQ6LWE64"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 26: Train Loss (Student): 2.8043 Acc (Labeled): 0.7976 | Val Loss (Student): 0.6829 Acc: 0.8389\n","Epoch 27: Train Loss (Student): 2.7596 Acc (Labeled): 0.8143 | Val Loss (Student): 0.5620 Acc: 0.8556\n","Epoch 28: Train Loss (Student): 2.6699 Acc (Labeled): 0.8238 | Val Loss (Student): 0.4682 Acc: 0.8833\n","Epoch 29: Train Loss (Student): 2.5936 Acc (Labeled): 0.8214 | Val Loss (Student): 0.4698 Acc: 0.8667\n","Epoch 30: Train Loss (Student): 2.5022 Acc (Labeled): 0.8238 | Val Loss (Student): 0.3828 Acc: 0.8667\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"wgaHVh0DL17B"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+31}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1763980360633,"user_tz":-420,"elapsed":390893,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"a6e7495e-77ad-4776-d34b-65cce81fcda3","id":"ebYALeASZbKO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 31: Train Loss (Student): 2.4667 Acc (Labeled): 0.8143 | Val Loss (Student): 0.4770 Acc: 0.8722\n","Epoch 32: Train Loss (Student): 2.4439 Acc (Labeled): 0.8429 | Val Loss (Student): 0.3129 Acc: 0.9111\n","Epoch 33: Train Loss (Student): 2.3199 Acc (Labeled): 0.8190 | Val Loss (Student): 0.3351 Acc: 0.8889\n","Epoch 34: Train Loss (Student): 2.3658 Acc (Labeled): 0.8595 | Val Loss (Student): 0.3397 Acc: 0.9000\n","Epoch 35: Train Loss (Student): 2.2309 Acc (Labeled): 0.8357 | Val Loss (Student): 0.4302 Acc: 0.8889\n"]}]},{"cell_type":"code","source":["for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+36}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')"],"metadata":{"id":"ew0AUFplcJR0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_6000.pth')"],"metadata":{"id":"Abdi16AcL17A"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#10 000SET"],"metadata":{"id":"dNGMMIO4FkHa"}},{"cell_type":"markdown","source":["##Distillation"],"metadata":{"id":"3nD7QTINFkHb"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764058632153,"user_tz":-420,"elapsed":58,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"2ab9f29a-63b2-4712-fd87-c28f79afba7d","id":"zhFLeQ8gFkHb"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","\n","# Instantiate MobileNetV2 without pretrained weights\n","student = models.mobilenet_v2(weights=None)\n","\n","# Replace the default classifier with a new linear layer for 2 classes\n","# The last_channel attribute gives the input features to the original classifier\n","num_classes = 2\n","student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n","\n","print(\"MobileNetV2 student model defined with classification head.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2 student model defined with classification head.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764058681173,"user_tz":-420,"elapsed":533,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"4803d38e-62c9-4082-8d11-a95fe2e92e5e","id":"OvgP47mRFkHb"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","\n","# Define the path to your saved finetuned teacher model checkpoint\n","finetuned_checkpoint_path = '/content/drive/MyDrive/mods/resnet_finetune_only.pth'\n","\n","# Load a standard ResNet50 model structure\n","teacher_model = models.resnet50(weights=None) # Load without pretrained ImageNet weights initially\n","\n","# Modify the final fully connected layer to match the number of classes\n","num_ftrs = teacher_model.fc.in_features\n","num_classes = 2  # Your model was finetuned for 2 classes (Cat/Dog)\n","teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n","\n","\n","# Load the state dictionary from the saved finetuned teacher model checkpoint\n","# Using map_location='cpu' to load onto CPU first is safer, then move to device\n","teacher_state_dict = torch.load(finetuned_checkpoint_path, map_location='cpu')\n","\n","# Load the state dictionary into the standard ResNet50 model\n","# This should now work because the model structure matches the saved state_dict\n","teacher_model.load_state_dict(teacher_state_dict)\n","\n","# Set the teacher model to evaluation mode\n","teacher_model.eval()\n","\n","# Freeze the teacher model parameters\n","for param in teacher_model.parameters():\n","    param.requires_grad = False\n","\n","# Determine the device based on CUDA availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the teacher model to the device\n","teacher_model = teacher_model.to(device)\n","\n","print(\"Finetuned teacher model loaded for distillation.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned teacher model loaded for distillation.\n"]}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- transforms ---\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# --- datasets ---\n","unlabeled = '/content/drive/MyDrive/pets/unlabeled_train'\n","labeled = '/content/drive/MyDrive/pets/finetune_train'\n","val = '/content/drive/MyDrive/pets/val'\n","\n","# Load datasets\n","labeled_dataset = datasets.ImageFolder(labeled, transform=train_transform)\n","unlabeled_dataset = datasets.ImageFolder(unlabeled, transform=train_transform)\n","\n","\n","# Replace labels for unlabeled samples with -1\n","unlabeled_dataset.samples = [(path, -1) for (path, _) in unlabeled_dataset.samples]\n","\n","BATCH_SIZE = 64\n","\n","# Combine\n","combined_dataset = ConcatDataset([labeled_dataset, unlabeled_dataset])\n","train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","val_dataset = datasets.ImageFolder(val, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"Number of images in the labeled dataset: {len(labeled_dataset)}\")\n","print(f\"Number of images in the unlabeled dataset: {len(unlabeled_dataset)}\")\n","print(f\"Number of images in the val dataset: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764058761647,"user_tz":-420,"elapsed":19919,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"2d2b6b7b-2547-4491-a055-da70045237a3","id":"yXRE-zw4FkHb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the labeled dataset: 420\n","Number of images in the unlabeled dataset: 10000\n","Number of images in the val dataset: 180\n"]}]},{"cell_type":"code","source":["ce_loss = nn.CrossEntropyLoss()\n","\n","def kd_loss(student_logits, teacher_logits, T):\n","    \"\"\"KL divergence loss for soft logits.\"\"\"\n","    p_s = F.log_softmax(student_logits / T, dim=1)\n","    p_t = F.softmax(teacher_logits / T, dim=1)\n","    return F.kl_div(p_s, p_t, reduction='batchmean') * (T * T)"],"metadata":{"id":"2hdHuhHtFkHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_distillation_epoch(student_model, teacher_model, dataloader, criterion_ce, criterion_kd, optimizer, T, device, alpha):\n","    student_model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get teacher and student outputs\n","        with torch.no_grad():\n","            teacher_logits = teacher_model(inputs)\n","        student_logits = student_model(inputs)\n","\n","        # Identify labeled and unlabeled samples\n","        labeled_mask = (labels != -1)\n","        unlabeled_mask = (labels == -1)\n","\n","        # Calculate loss for labeled data (Cross-Entropy)\n","        ce_loss = criterion_ce(student_logits[labeled_mask], labels[labeled_mask]) if labeled_mask.sum() > 0 else 0\n","\n","        # Calculate loss for unlabeled data (KL Divergence)\n","        kd_loss_val = criterion_kd(student_logits[unlabeled_mask], teacher_logits[unlabeled_mask], T) if unlabeled_mask.sum() > 0 else 0\n","\n","        # Combine losses\n","        loss = (1 - alpha) * ce_loss + alpha * kd_loss_val\n","\n","        # Backpropagate and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss and accuracy\n","        running_loss += loss.item() * inputs.size(0)\n","        # For accuracy, only consider labeled data\n","        if labeled_mask.sum() > 0:\n","            _, preds = torch.max(student_logits[labeled_mask], 1)\n","            correct += (preds == labels[labeled_mask]).sum().item()\n","            total += labeled_mask.sum().item()\n","\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / total if total > 0 else 0.0\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"OMOVyL66FkHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc"],"metadata":{"id":"YIUpDQouFkHc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_student = torch.optim.Adam(student.parameters(), lr=3e-4) # Define optimizer for student\n","T = 5.0 # Temperature for KL divergence\n","alpha = 0.8\n","# Move student model to device\n","student = student.to(device)\n","\n","for epoch in range(15):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+1}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764062580147,"user_tz":-420,"elapsed":3709758,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"87317f32-4b75-4583-ae93-c3087020c4b9","id":"uYC0rc6tFkHc"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1: Train Loss (Student): 5.6798 Acc (Labeled): 0.5738 | Val Loss (Student): 0.8933 Acc: 0.6111\n","Epoch 2: Train Loss (Student): 5.3400 Acc (Labeled): 0.6095 | Val Loss (Student): 1.3802 Acc: 0.6000\n","Epoch 3: Train Loss (Student): 5.0225 Acc (Labeled): 0.6405 | Val Loss (Student): 0.7372 Acc: 0.7333\n","Epoch 4: Train Loss (Student): 4.8159 Acc (Labeled): 0.6929 | Val Loss (Student): 0.5996 Acc: 0.7111\n","Epoch 5: Train Loss (Student): 4.6569 Acc (Labeled): 0.6857 | Val Loss (Student): 0.7013 Acc: 0.7444\n","Epoch 6: Train Loss (Student): 4.4295 Acc (Labeled): 0.6857 | Val Loss (Student): 0.6367 Acc: 0.7333\n","Epoch 7: Train Loss (Student): 4.3009 Acc (Labeled): 0.7238 | Val Loss (Student): 0.6250 Acc: 0.7833\n","Epoch 8: Train Loss (Student): 4.1574 Acc (Labeled): 0.7429 | Val Loss (Student): 0.8455 Acc: 0.7667\n","Epoch 9: Train Loss (Student): 4.0118 Acc (Labeled): 0.7310 | Val Loss (Student): 0.5925 Acc: 0.8222\n","Epoch 10: Train Loss (Student): 3.9256 Acc (Labeled): 0.7524 | Val Loss (Student): 0.6006 Acc: 0.8278\n","Epoch 11: Train Loss (Student): 3.8446 Acc (Labeled): 0.7690 | Val Loss (Student): 0.5108 Acc: 0.8389\n","Epoch 12: Train Loss (Student): 3.6914 Acc (Labeled): 0.7095 | Val Loss (Student): 0.7430 Acc: 0.8000\n","Epoch 13: Train Loss (Student): 3.4331 Acc (Labeled): 0.7762 | Val Loss (Student): 0.7667 Acc: 0.8167\n","Epoch 14: Train Loss (Student): 3.3959 Acc (Labeled): 0.7833 | Val Loss (Student): 0.5861 Acc: 0.8333\n","Epoch 15: Train Loss (Student): 3.2967 Acc (Labeled): 0.7738 | Val Loss (Student): 0.4481 Acc: 0.8722\n"]}]},{"cell_type":"markdown","source":["##Distillation (2)"],"metadata":{"id":"aJuu0kbhTAvU"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764146266071,"user_tz":-420,"elapsed":2537,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"f5109799-5d1e-4221-bd07-667cda49385a","id":"S1kZ75WFTAvV"},"source":["import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","# Instantiate MobileNetV2 without pretrained weights\n","student = models.mobilenet_v2(weights=None)\n","\n","# Replace the default classifier with a new linear layer for 2 classes\n","# The last_channel attribute gives the input features to the original classifier\n","num_classes = 2\n","student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n","\n","student_state_dict = torch.load('/content/drive/MyDrive/mods/only_distilled_student_10000.pth', map_location='cpu')\n","\n","student.load_state_dict(student_state_dict, strict=True)\n","\n","# Move the model to the appropriate device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","student = student.to(device)\n","print(\"MobileNetV2 student model defined with classification head.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2 student model defined with classification head.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764146286142,"user_tz":-420,"elapsed":8773,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"001388a4-0654-4687-d876-600a9d87a3ff","id":"AHaEBkZsTAvV"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","\n","# Define the path to your saved finetuned teacher model checkpoint\n","finetuned_checkpoint_path = '/content/drive/MyDrive/mods/resnet_finetune_only.pth'\n","\n","# Load a standard ResNet50 model structure\n","teacher_model = models.resnet50(weights=None) # Load without pretrained ImageNet weights initially\n","\n","# Modify the final fully connected layer to match the number of classes\n","num_ftrs = teacher_model.fc.in_features\n","num_classes = 2  # Your model was finetuned for 2 classes (Cat/Dog)\n","teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n","\n","\n","# Load the state dictionary from the saved finetuned teacher model checkpoint\n","# Using map_location='cpu' to load onto CPU first is safer, then move to device\n","teacher_state_dict = torch.load(finetuned_checkpoint_path, map_location='cpu')\n","\n","# Load the state dictionary into the standard ResNet50 model\n","# This should now work because the model structure matches the saved state_dict\n","teacher_model.load_state_dict(teacher_state_dict)\n","\n","# Set the teacher model to evaluation mode\n","teacher_model.eval()\n","\n","# Freeze the teacher model parameters\n","for param in teacher_model.parameters():\n","    param.requires_grad = False\n","\n","# Determine the device based on CUDA availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the teacher model to the device\n","teacher_model = teacher_model.to(device)\n","\n","print(\"Finetuned teacher model loaded for distillation.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned teacher model loaded for distillation.\n"]}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- transforms ---\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# --- datasets ---\n","unlabeled = '/content/drive/MyDrive/pets/unlabeled_train'\n","labeled = '/content/drive/MyDrive/pets/finetune_train'\n","val = '/content/drive/MyDrive/pets/val'\n","\n","# Load datasets\n","labeled_dataset = datasets.ImageFolder(labeled, transform=train_transform)\n","unlabeled_dataset = datasets.ImageFolder(unlabeled, transform=train_transform)\n","\n","\n","# Replace labels for unlabeled samples with -1\n","unlabeled_dataset.samples = [(path, -1) for (path, _) in unlabeled_dataset.samples]\n","\n","BATCH_SIZE = 64\n","\n","# Combine\n","combined_dataset = ConcatDataset([labeled_dataset, unlabeled_dataset])\n","train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","val_dataset = datasets.ImageFolder(val, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"Number of images in the labeled dataset: {len(labeled_dataset)}\")\n","print(f\"Number of images in the unlabeled dataset: {len(unlabeled_dataset)}\")\n","print(f\"Number of images in the val dataset: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764146319202,"user_tz":-420,"elapsed":22964,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"d9365de6-cff8-43d6-b02c-523434149f52","id":"fdfbQGvRTAvV"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the labeled dataset: 420\n","Number of images in the unlabeled dataset: 10000\n","Number of images in the val dataset: 180\n"]}]},{"cell_type":"code","source":["ce_loss = nn.CrossEntropyLoss()\n","\n","def kd_loss(student_logits, teacher_logits, T):\n","    \"\"\"KL divergence loss for soft logits.\"\"\"\n","    p_s = F.log_softmax(student_logits / T, dim=1)\n","    p_t = F.softmax(teacher_logits / T, dim=1)\n","    return F.kl_div(p_s, p_t, reduction='batchmean') * (T * T)"],"metadata":{"id":"jea4ctniTAvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_distillation_epoch(student_model, teacher_model, dataloader, criterion_ce, criterion_kd, optimizer, T, device, alpha):\n","    student_model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get teacher and student outputs\n","        with torch.no_grad():\n","            teacher_logits = teacher_model(inputs)\n","        student_logits = student_model(inputs)\n","\n","        # Identify labeled and unlabeled samples\n","        labeled_mask = (labels != -1)\n","        unlabeled_mask = (labels == -1)\n","\n","        # Calculate loss for labeled data (Cross-Entropy)\n","        ce_loss = criterion_ce(student_logits[labeled_mask], labels[labeled_mask]) if labeled_mask.sum() > 0 else 0\n","\n","        # Calculate loss for unlabeled data (KL Divergence)\n","        kd_loss_val = criterion_kd(student_logits[unlabeled_mask], teacher_logits[unlabeled_mask], T) if unlabeled_mask.sum() > 0 else 0\n","\n","        # Combine losses\n","        loss = (1 - alpha) * ce_loss + alpha * kd_loss_val\n","\n","        # Backpropagate and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss and accuracy\n","        running_loss += loss.item() * inputs.size(0)\n","        # For accuracy, only consider labeled data\n","        if labeled_mask.sum() > 0:\n","            _, preds = torch.max(student_logits[labeled_mask], 1)\n","            correct += (preds == labels[labeled_mask]).sum().item()\n","            total += labeled_mask.sum().item()\n","\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / total if total > 0 else 0.0\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"qv6E88e1TAvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc"],"metadata":{"id":"eBJwkN5LTAvW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_student = torch.optim.Adam(student.parameters(), lr=3e-4) # Define optimizer for student\n","T = 5.0 # Temperature for KL divergence\n","alpha = 0.8\n","# Move student model to device\n","#student = student.to(device)\n","\n","for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+16}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764151518800,"user_tz":-420,"elapsed":5055207,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"123b51d7-8cf8-4900-e7c9-381587fb3933","id":"WY-ME7PqTAvW"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 16: Train Loss (Student): 3.1788 Acc (Labeled): 0.7762 | Val Loss (Student): 0.4500 Acc: 0.8444\n","Epoch 17: Train Loss (Student): 3.0052 Acc (Labeled): 0.7952 | Val Loss (Student): 0.4444 Acc: 0.8611\n","Epoch 18: Train Loss (Student): 2.8918 Acc (Labeled): 0.7976 | Val Loss (Student): 0.4829 Acc: 0.8722\n","Epoch 19: Train Loss (Student): 2.7401 Acc (Labeled): 0.8238 | Val Loss (Student): 0.3349 Acc: 0.8944\n","Epoch 20: Train Loss (Student): 2.6777 Acc (Labeled): 0.8143 | Val Loss (Student): 0.3769 Acc: 0.8778\n","Epoch 21: Train Loss (Student): 2.4268 Acc (Labeled): 0.8357 | Val Loss (Student): 0.3770 Acc: 0.8833\n","Epoch 22: Train Loss (Student): 2.4466 Acc (Labeled): 0.8357 | Val Loss (Student): 0.5768 Acc: 0.8500\n","Epoch 23: Train Loss (Student): 2.2970 Acc (Labeled): 0.8571 | Val Loss (Student): 0.4746 Acc: 0.8833\n","Epoch 24: Train Loss (Student): 2.2736 Acc (Labeled): 0.8381 | Val Loss (Student): 0.3630 Acc: 0.9056\n","Epoch 25: Train Loss (Student): 2.1969 Acc (Labeled): 0.8500 | Val Loss (Student): 0.3842 Acc: 0.9056\n"]}]},{"cell_type":"code","source":["torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_cont.pth')"],"metadata":{"id":"rllS56FkTAvX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##Distillation (3)"],"metadata":{"id":"WLuQs948ylOM"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764236216046,"user_tz":-420,"elapsed":10781,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"82b1e579-62cd-4b13-ab78-648bc6dd506a","id":"uVkK2nfUylON"},"source":["import torch\n","import torchvision.models as models\n","import torch.nn as nn\n","\n","# Instantiate MobileNetV2 without pretrained weights\n","student = models.mobilenet_v2(weights=None)\n","\n","# Replace the default classifier with a new linear layer for 2 classes\n","# The last_channel attribute gives the input features to the original classifier\n","num_classes = 2\n","student.classifier[1] = nn.Linear(student.last_channel, num_classes)\n","\n","student_state_dict = torch.load('/content/drive/MyDrive/mods/only_distilled_student_10000_cont.pth', map_location='cpu')\n","\n","student.load_state_dict(student_state_dict, strict=True)\n","\n","# Move the model to the appropriate device\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","student = student.to(device)\n","print(\"MobileNetV2 student model defined with classification head.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["MobileNetV2 student model defined with classification head.\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764236237849,"user_tz":-420,"elapsed":5549,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"31f15ac7-2495-4c8f-823b-1eaa62df0b22","id":"gX98gudUylOO"},"source":["import torchvision.models as models\n","import torch.nn as nn\n","import torch\n","\n","# Define the path to your saved finetuned teacher model checkpoint\n","finetuned_checkpoint_path = '/content/drive/MyDrive/mods/resnet_finetune_only.pth'\n","\n","# Load a standard ResNet50 model structure\n","teacher_model = models.resnet50(weights=None) # Load without pretrained ImageNet weights initially\n","\n","# Modify the final fully connected layer to match the number of classes\n","num_ftrs = teacher_model.fc.in_features\n","num_classes = 2  # Your model was finetuned for 2 classes (Cat/Dog)\n","teacher_model.fc = nn.Linear(num_ftrs, num_classes)\n","\n","\n","# Load the state dictionary from the saved finetuned teacher model checkpoint\n","# Using map_location='cpu' to load onto CPU first is safer, then move to device\n","teacher_state_dict = torch.load(finetuned_checkpoint_path, map_location='cpu')\n","\n","# Load the state dictionary into the standard ResNet50 model\n","# This should now work because the model structure matches the saved state_dict\n","teacher_model.load_state_dict(teacher_state_dict)\n","\n","# Set the teacher model to evaluation mode\n","teacher_model.eval()\n","\n","# Freeze the teacher model parameters\n","for param in teacher_model.parameters():\n","    param.requires_grad = False\n","\n","# Determine the device based on CUDA availability\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","# Move the teacher model to the device\n","teacher_model = teacher_model.to(device)\n","\n","print(\"Finetuned teacher model loaded for distillation.\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Finetuned teacher model loaded for distillation.\n"]}]},{"cell_type":"code","source":["from torchvision import datasets, transforms\n","from torch.utils.data import Dataset, DataLoader, ConcatDataset\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","# --- transforms ---\n","train_transform = transforms.Compose([\n","    transforms.RandomResizedCrop(224),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","val_transform = transforms.Compose([\n","    transforms.Resize(224),\n","    transforms.CenterCrop(224),\n","    transforms.ToTensor(),\n","    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n","                         std=[0.229, 0.224, 0.225])\n","])\n","\n","# --- datasets ---\n","unlabeled = '/content/drive/MyDrive/pets/unlabeled_train'\n","labeled = '/content/drive/MyDrive/pets/finetune_train'\n","val = '/content/drive/MyDrive/pets/val'\n","\n","# Load datasets\n","labeled_dataset = datasets.ImageFolder(labeled, transform=train_transform)\n","unlabeled_dataset = datasets.ImageFolder(unlabeled, transform=train_transform)\n","\n","\n","# Replace labels for unlabeled samples with -1\n","unlabeled_dataset.samples = [(path, -1) for (path, _) in unlabeled_dataset.samples]\n","\n","BATCH_SIZE = 64\n","\n","# Combine\n","combined_dataset = ConcatDataset([labeled_dataset, unlabeled_dataset])\n","train_loader = DataLoader(combined_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2)\n","\n","val_dataset = datasets.ImageFolder(val, transform=val_transform)\n","val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n","\n","print(f\"Number of images in the labeled dataset: {len(labeled_dataset)}\")\n","print(f\"Number of images in the unlabeled dataset: {len(unlabeled_dataset)}\")\n","print(f\"Number of images in the val dataset: {len(val_dataset)}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764236259866,"user_tz":-420,"elapsed":17599,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"53cb851c-5af4-41bd-dc25-a79d760fcd01","id":"YKwT3fdRylOO"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Number of images in the labeled dataset: 420\n","Number of images in the unlabeled dataset: 10000\n","Number of images in the val dataset: 180\n"]}]},{"cell_type":"code","source":["ce_loss = nn.CrossEntropyLoss()\n","\n","def kd_loss(student_logits, teacher_logits, T):\n","    \"\"\"KL divergence loss for soft logits.\"\"\"\n","    p_s = F.log_softmax(student_logits / T, dim=1)\n","    p_t = F.softmax(teacher_logits / T, dim=1)\n","    return F.kl_div(p_s, p_t, reduction='batchmean') * (T * T)"],"metadata":{"id":"qobeT08uylOO"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def train_distillation_epoch(student_model, teacher_model, dataloader, criterion_ce, criterion_kd, optimizer, T, device, alpha):\n","    student_model.train()\n","    running_loss = 0.0\n","    correct = 0\n","    total = 0\n","\n","    for inputs, labels in dataloader:\n","        inputs, labels = inputs.to(device), labels.to(device)\n","\n","        optimizer.zero_grad()\n","\n","        # Get teacher and student outputs\n","        with torch.no_grad():\n","            teacher_logits = teacher_model(inputs)\n","        student_logits = student_model(inputs)\n","\n","        # Identify labeled and unlabeled samples\n","        labeled_mask = (labels != -1)\n","        unlabeled_mask = (labels == -1)\n","\n","        # Calculate loss for labeled data (Cross-Entropy)\n","        ce_loss = criterion_ce(student_logits[labeled_mask], labels[labeled_mask]) if labeled_mask.sum() > 0 else 0\n","\n","        # Calculate loss for unlabeled data (KL Divergence)\n","        kd_loss_val = criterion_kd(student_logits[unlabeled_mask], teacher_logits[unlabeled_mask], T) if unlabeled_mask.sum() > 0 else 0\n","\n","        # Combine losses\n","        loss = (1 - alpha) * ce_loss + alpha * kd_loss_val\n","\n","        # Backpropagate and optimize\n","        loss.backward()\n","        optimizer.step()\n","\n","        # Update running loss and accuracy\n","        running_loss += loss.item() * inputs.size(0)\n","        # For accuracy, only consider labeled data\n","        if labeled_mask.sum() > 0:\n","            _, preds = torch.max(student_logits[labeled_mask], 1)\n","            correct += (preds == labels[labeled_mask]).sum().item()\n","            total += labeled_mask.sum().item()\n","\n","\n","    epoch_loss = running_loss / len(dataloader.dataset)\n","    epoch_acc = correct / total if total > 0 else 0.0\n","    return epoch_loss, epoch_acc"],"metadata":{"id":"SuI3hJeYylOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def validate(model, dataloader, criterion):\n","    model.eval()\n","    running_loss = 0\n","    correct = 0\n","    total = 0\n","\n","    with torch.no_grad():\n","        for imgs, labels in dataloader:\n","            imgs, labels = imgs.to(device), labels.to(device)\n","            outputs = model(imgs)\n","            loss = criterion(outputs, labels)\n","\n","            running_loss += loss.item() * imgs.size(0)\n","            _, preds = torch.max(outputs, 1)\n","            correct += (preds == labels).sum().item()\n","            total += labels.size(0)\n","\n","    val_loss = running_loss / total\n","    val_acc = correct / total\n","    return val_loss, val_acc"],"metadata":{"id":"YOzOCDdjylOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["optimizer_student = torch.optim.Adam(student.parameters(), lr=3e-4) # Define optimizer for student\n","T = 5.0 # Temperature for KL divergence\n","alpha = 0.8\n","# Move student model to device\n","#student = student.to(device)\n","\n","for epoch in range(10):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    print(f'Epoch {epoch+26}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n","    if (epoch+1)%5 == 0:\n","        torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_epoch.pth')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764239518853,"user_tz":-420,"elapsed":3025318,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"1066873d-776f-4f1e-a97a-c0e90a90d110","id":"c3LMDKK6ylOP"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 26: Train Loss (Student): 2.1166 Acc (Labeled): 0.8429 | Val Loss (Student): 0.2889 Acc: 0.9389\n","Epoch 27: Train Loss (Student): 2.0745 Acc (Labeled): 0.8595 | Val Loss (Student): 0.3250 Acc: 0.9111\n","Epoch 28: Train Loss (Student): 1.9576 Acc (Labeled): 0.8643 | Val Loss (Student): 0.3833 Acc: 0.9000\n","Epoch 29: Train Loss (Student): 1.8979 Acc (Labeled): 0.8643 | Val Loss (Student): 0.2492 Acc: 0.9167\n","Epoch 30: Train Loss (Student): 1.8586 Acc (Labeled): 0.8738 | Val Loss (Student): 0.2342 Acc: 0.9333\n","Epoch 31: Train Loss (Student): 1.7760 Acc (Labeled): 0.8571 | Val Loss (Student): 0.2642 Acc: 0.9333\n","Epoch 32: Train Loss (Student): 1.7745 Acc (Labeled): 0.8571 | Val Loss (Student): 0.2064 Acc: 0.9444\n","Epoch 33: Train Loss (Student): 1.7592 Acc (Labeled): 0.8595 | Val Loss (Student): 0.1629 Acc: 0.9444\n","Epoch 34: Train Loss (Student): 1.7221 Acc (Labeled): 0.8714 | Val Loss (Student): 0.1835 Acc: 0.9444\n","Epoch 35: Train Loss (Student): 1.6156 Acc (Labeled): 0.8714 | Val Loss (Student): 0.1622 Acc: 0.9500\n"]}]},{"cell_type":"code","source":["torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_cont.pth')"],"metadata":{"id":"nVWbBdR4ylOP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(8):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    if (epoch+1)%2 == 0:\n","        torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_epoch.pth')\n","\n","    print(f'Epoch {epoch+36}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MMj-rxLN30nP","executionInfo":{"status":"ok","timestamp":1764240709403,"user_tz":-420,"elapsed":1033825,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"ca930f28-fe4e-480c-feaf-951e8df43726"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 36: Train Loss (Student): 1.5906 Acc (Labeled): 0.8976 | Val Loss (Student): 0.1992 Acc: 0.9389\n","Epoch 37: Train Loss (Student): 1.5353 Acc (Labeled): 0.8690 | Val Loss (Student): 0.3305 Acc: 0.9222\n","Epoch 38: Train Loss (Student): 1.4961 Acc (Labeled): 0.8881 | Val Loss (Student): 0.2045 Acc: 0.9500\n","Epoch 39: Train Loss (Student): 1.4350 Acc (Labeled): 0.9000 | Val Loss (Student): 0.1600 Acc: 0.9500\n","Epoch 40: Train Loss (Student): 1.4505 Acc (Labeled): 0.8952 | Val Loss (Student): 0.1887 Acc: 0.9389\n","Epoch 41: Train Loss (Student): 1.4318 Acc (Labeled): 0.8929 | Val Loss (Student): 0.1660 Acc: 0.9611\n","Epoch 42: Train Loss (Student): 1.3724 Acc (Labeled): 0.8738 | Val Loss (Student): 0.2022 Acc: 0.9389\n","Epoch 43: Train Loss (Student): 1.3654 Acc (Labeled): 0.9167 | Val Loss (Student): 0.2422 Acc: 0.9389\n"]}]},{"cell_type":"code","source":["valloss = 0.94\n","for epoch in range(5):\n","    train_loss_student, train_acc_student = train_distillation_epoch(\n","        student, teacher_model, train_loader, ce_loss, kd_loss, optimizer_student, T, device, alpha\n","    )\n","    val_loss_student, val_acc_student = validate(student, val_loader, ce_loss)\n","\n","    if (epoch+1)%2 == 0:\n","        torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_epoch.pth')\n","    if val_loss_student < valloss:\n","        valloss = val_loss_student\n","        torch.save(student.state_dict(), '/content/drive/MyDrive/mods/only_distilled_student_10000_cont.pth')\n","\n","    print(f'Epoch {epoch+44}: '\n","          f'Train Loss (Student): {train_loss_student:.4f} Acc (Labeled): {train_acc_student:.4f} | '\n","          f'Val Loss (Student): {val_loss_student:.4f} Acc: {val_acc_student:.4f}')\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1764241630963,"user_tz":-420,"elapsed":639512,"user":{"displayName":"Trang Ho","userId":"06685644430566655680"}},"outputId":"af03e3e1-17c7-453e-a478-edf5fdefc17f","id":"yMKOVQpg8X-c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 44: Train Loss (Student): 1.2921 Acc (Labeled): 0.8881 | Val Loss (Student): 0.2864 Acc: 0.9333\n","Epoch 45: Train Loss (Student): 1.3278 Acc (Labeled): 0.8952 | Val Loss (Student): 0.1995 Acc: 0.9389\n","Epoch 46: Train Loss (Student): 1.2949 Acc (Labeled): 0.9095 | Val Loss (Student): 0.1766 Acc: 0.9500\n","Epoch 47: Train Loss (Student): 1.2747 Acc (Labeled): 0.8905 | Val Loss (Student): 0.1520 Acc: 0.9500\n","Epoch 48: Train Loss (Student): 1.2877 Acc (Labeled): 0.9048 | Val Loss (Student): 0.2678 Acc: 0.9444\n"]}]}]}